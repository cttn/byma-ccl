#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os, json, logging, io, asyncio, fcntl, uuid
from datetime import datetime
from pathlib import Path
from contextlib import contextmanager

import numpy as np
import pandas as pd
import yfinance as yf
import requests

import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
from matplotlib import colormaps
from matplotlib.colors import Normalize

from telegram import Update
from telegram.ext import Application, CommandHandler, ContextTypes

# ---------------------- CONFIG ----------------------
TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "REEMPLAZA_CON_TU_TOKEN")
STATE_FILE = Path("state.json")  # persistencia por chat_id

log_level = os.getenv("LOG_LEVEL", "INFO").upper()
configured_level = getattr(logging, log_level, None)
logging.basicConfig(
    level=configured_level if isinstance(configured_level, int) else logging.INFO,
    format="%(asctime)s %(name)s %(module)s:%(lineno)d %(levelname)s %(message)s",
    force=True,
)
if not isinstance(configured_level, int):
    logging.warning("Invalid LOG_LEVEL %s, defaulting to INFO", log_level)
log = logging.getLogger("ccl-bot")

# ------------------ LOGGING HELPERS -----------------
def log_exception_with_id(message: str, *, exc: BaseException, **context) -> str:
    """Log ``exc`` with an autogenerated ``error_id`` and return it."""

    error_id = uuid.uuid4().hex[:8]
    ctx = " ".join(f"{key}={value}" for key, value in context.items() if value is not None)
    ctx_suffix = f" {ctx}" if ctx else ""
    log.error(
        "%s error_id=%s%s exception=%s",
        message,
        error_id,
        ctx_suffix,
        exc,
        exc_info=True,
    )
    return error_id

# ------------------ FILE LOCKING -------------------
@contextmanager
def _locked_file(file_obj, lock_type: int):
    fcntl.flock(file_obj.fileno(), lock_type)
    try:
        yield file_obj
    finally:
        fcntl.flock(file_obj.fileno(), fcntl.LOCK_UN)

# ------------------ UTIL / PERSISTENCIA -------------
def load_state() -> dict:
    if STATE_FILE.exists():
        try:
            with STATE_FILE.open("r", encoding="utf-8") as file_obj:
                with _locked_file(file_obj, fcntl.LOCK_SH) as locked:
                    size = os.fstat(locked.fileno()).st_size
                    log.debug(
                        "Loading state from %s (%s bytes)",
                        STATE_FILE.resolve(),
                        size,
                    )
                    data = locked.read()
            state = json.loads(data)
            log.debug(
                "Loaded state from %s (%s bytes)",
                STATE_FILE.resolve(),
                size,
            )
            return state
        except Exception as ex:
            log.error(f"Error loading state from {STATE_FILE.resolve()}: {ex}")
    else:
        log.debug(f"State file {STATE_FILE.resolve()} does not exist")
    return {}

def save_state(state: dict, chat_id: int | None = None) -> None:
    try:
        data = json.dumps(state, ensure_ascii=False, indent=2)
        STATE_FILE.parent.mkdir(parents=True, exist_ok=True)
        log.debug(
            "Saving state to %s (%s bytes)",
            STATE_FILE.resolve(),
            len(data),
        )
        mode = "r+" if STATE_FILE.exists() else "w"
        with STATE_FILE.open(mode, encoding="utf-8") as file_obj:
            with _locked_file(file_obj, fcntl.LOCK_EX) as locked:
                locked.seek(0)
                locked.truncate()
                locked.write(data)
                locked.flush()
                os.fsync(locked.fileno())
                final_size = os.fstat(locked.fileno()).st_size
        log.debug(
            "Saved state to %s (%s bytes)",
            STATE_FILE.resolve(),
            final_size,
        )
    except Exception as ex:
        if chat_id is not None:
            log.error(f"Error saving state for chat_id={chat_id} to {STATE_FILE.resolve()}: {ex}")
        else:
            log.error(f"Error saving state to {STATE_FILE.resolve()}: {ex}")

def get_chat_state(chat_id: int) -> dict:
    st = load_state().get(str(chat_id), {})
    # defaults
    if "normalize" not in st:
        st["normalize"] = False
    return st

def set_chat_state(chat_id: int, **kwargs):
    state = load_state()
    st = state.get(str(chat_id), {})
    st.update(kwargs)
    state[str(chat_id)] = st
    save_state(state, chat_id)

def set_date(chat_id: int, key: str, value: str):
    set_chat_state(chat_id, **{key: value})

def get_dates(chat_id: int):
    st = get_chat_state(chat_id)
    return st.get("start"), st.get("end")

def get_normalize(chat_id: int) -> bool:
    value = bool(get_chat_state(chat_id).get("normalize", False))
    log.debug(f"chat_id={chat_id} normalize={value}")
    return value

def toggle_normalize(chat_id: int) -> bool:
    current = get_normalize(chat_id)
    new_state = not current
    set_chat_state(chat_id, normalize=new_state)
    log.info(f"chat_id={chat_id} normalize toggled {current} -> {new_state}")
    return new_state

def parse_date(s: str) -> str:
    return datetime.strptime(s, "%Y-%m-%d").date().isoformat()

def norm_ticker_ba(t: str) -> str:
    t = t.strip().upper()
    if not t.endswith(".BA"):
        t += ".BA"
    return t

def prettify_symbol(s: str) -> str:
    return s.replace(".BA", "")

# ------------------ NÚCLEO FINANCIERO ----------------
TICKERS = [norm_ticker_ba(x) for x in [
    'ALUA','BMA','BYMA','CEPU','COME','CRES','CVH','EDN','GGAL','MIRG',
    'PAMP','SUPV','TECO2','TGNO4','TGSU2','TRAN','TXAR','VALO','YPFD',
    'DOME','AGRO','AUSO','BBAR','BHIP','BPAT','CADO','CAPX','CARC',
    'CELU','CGPA2','CTIO','DGCU2','DYCA','FERR','FIPL','BOLT','A3',
    'GARO','GBAN','GCLA','GRIM','HARG','HAVA','INTR','INVJ','IRSA',
    'LEDE','LOMA','LONG','METR','MOLA','MOLI','MORI','OEST','PATA',
    'POLL','RICH','RIGO','ROSE','SAMI','SEMI'
]]

def download_ccl(start: str, end: str) -> pd.Series:
    """CCL = YPFD.BA / YPF (Close)."""
    try:
        log.info("download_ccl request %s start=%s end=%s", "YPFD.BA", start, end)
        df_ars = yf.download(["YPFD.BA"], start=start, end=end, auto_adjust=True, progress=False)
        log.info(
            "download_ccl response %s shape=%s index_range=%s→%s",
            "YPFD.BA",
            getattr(df_ars, "shape", None),
            df_ars.index.min() if getattr(df_ars, "index", None) is not None and not df_ars.index.empty else None,
            df_ars.index.max() if getattr(df_ars, "index", None) is not None and not df_ars.index.empty else None,
        )
    except Exception as ex:
        log.error("download_ccl error downloading %s: %s", "YPFD.BA", ex, exc_info=True)
        raise
    try:
        log.info("download_ccl request %s start=%s end=%s", "YPF", start, end)
        df_us = yf.download(["YPF"], start=start, end=end, auto_adjust=True, progress=False)
        log.info(
            "download_ccl response %s shape=%s index_range=%s→%s",
            "YPF",
            getattr(df_us, "shape", None),
            df_us.index.min() if getattr(df_us, "index", None) is not None and not df_us.index.empty else None,
            df_us.index.max() if getattr(df_us, "index", None) is not None and not df_us.index.empty else None,
        )
    except Exception as ex:
        log.error("download_ccl error downloading %s: %s", "YPF", ex, exc_info=True)
        raise
    # Normalizar índices para evitar problemas de zona horaria
    for df in (df_ars, df_us):
        if isinstance(df.index, pd.DatetimeIndex):
            df.index = (df.index.tz_convert('UTC').tz_localize(None)
                        if df.index.tz is not None else df.index.tz_localize(None))
    ypf_ars = df_ars["Close"]["YPFD.BA"] if isinstance(df_ars["Close"], pd.DataFrame) else df_ars["Close"]
    ypf_usd = df_us["Close"]["YPF"]     if isinstance(df_us["Close"],  pd.DataFrame) else df_us["Close"]
    ccl = (ypf_ars / ypf_usd).to_frame("CCL").asfreq("D").ffill().bfill()["CCL"]
    if isinstance(ccl.index, pd.DatetimeIndex):
        ccl.index = (ccl.index.tz_convert('UTC').tz_localize(None)
                     if ccl.index.tz is not None else ccl.index.tz_localize(None))
    idx = getattr(ccl, "index", None)
    index_min = idx.min() if idx is not None and not idx.empty else None
    index_max = idx.max() if idx is not None and not idx.empty else None
    log.debug(
        "download_ccl result size=%s index_range=%s→%s",
        ccl.size,
        index_min,
        index_max,
    )
    return ccl

def get_var(start: str, end: str) -> tuple[pd.Series, str]:
    """Retornos en USD (vía CCL) entre start y end, ordenados ascendente (%)."""
    data: dict[str, pd.Series] = {}
    failed: list[str] = []

    def normalize_index(obj: pd.DataFrame | pd.Series) -> pd.DataFrame | pd.Series:
        if isinstance(obj.index, pd.DatetimeIndex):
            obj.index = (
                obj.index.tz_convert("UTC").tz_localize(None)
                if obj.index.tz is not None
                else obj.index.tz_localize(None)
            )
        return obj

    def mark_failed(ticker: str, reason: str) -> None:
        if ticker not in failed:
            log.warning(f"Fallo descargando {ticker}: {reason}")
            failed.append(ticker)

    try:
        bulk = yf.download(
            TICKERS,
            start=start,
            end=end,
            auto_adjust=True,
            progress=False,
            threads=False,
        )
        idx = getattr(bulk, "index", None)
        index_min = idx.min() if idx is not None and not getattr(idx, "empty", True) else None
        index_max = idx.max() if idx is not None and not getattr(idx, "empty", True) else None
        log.info(
            "get_var bulk download shape=%s index_range=%s→%s",
            getattr(bulk, "shape", None),
            index_min,
            index_max,
        )
    except (TimeoutError, requests.exceptions.RequestException, Exception) as ex:
        log.warning("get_var descarga masiva fallida: %s", ex)
        for ticker in TICKERS:
            mark_failed(ticker, str(ex))
        bulk = None

    close = None
    if isinstance(bulk, pd.DataFrame) and not bulk.empty:
        try:
            close = bulk["Close"]
        except KeyError:
            close = None
    elif isinstance(bulk, pd.Series) and not bulk.empty:
        close = bulk

    if close is None or (hasattr(close, "empty") and close.empty):
        for ticker in TICKERS:
            mark_failed(ticker, "sin datos en descarga masiva")
    else:
        if isinstance(close, pd.Series):
            name = close.name if isinstance(close.name, str) else TICKERS[0]
            close = close.to_frame(name)
        normalize_index(close)
        for ticker in TICKERS:
            if ticker not in close.columns:
                mark_failed(ticker, "sin datos en descarga masiva")
                continue
            ser = close[ticker]
            if isinstance(ser, pd.DataFrame):
                ser = ser.iloc[:, 0]
            if ser.dropna().empty:
                mark_failed(ticker, "serie vacía en descarga masiva")
                continue
            data[ticker] = ser

    failed = [ticker for ticker in failed if ticker not in data]

    if failed:
        retry_fail: list[str] = []
        for t in failed:
            try:
                df = yf.download(
                    [t],
                    start=start,
                    end=end,
                    auto_adjust=True,
                    progress=False,
                    timeout=30,
                )
            except (TimeoutError, requests.exceptions.RequestException, Exception) as ex:
                log.warning(f"Reintento fallido para {t}: {ex}")
                retry_fail.append(t)
                continue

            if "Close" not in df:
                retry_fail.append(t)
                continue

            ser = df["Close"][t] if isinstance(df["Close"], pd.DataFrame) else df["Close"]
            normalize_index(ser)
            if ser.dropna().empty:
                retry_fail.append(t)
                continue
            data[t] = ser
        failed = retry_fail

    if not data:
        raise RuntimeError("No se pudieron descargar precios.")

    close = pd.DataFrame(data)
    if isinstance(close.index, pd.DatetimeIndex):
        close.index = (close.index.tz_convert('UTC').tz_localize(None)
                       if close.index.tz is not None else close.index.tz_localize(None))

    ccl = download_ccl(start, end).to_frame().ffill()
    if isinstance(ccl.index, pd.DatetimeIndex):
        ccl.index = (ccl.index.tz_convert('UTC').tz_localize(None)
                     if ccl.index.tz is not None else ccl.index.tz_localize(None))
    close_usd = close.div(ccl["CCL"], axis=0)

    var = (close_usd.iloc[-1] / close_usd.iloc[0] - 1.0) * 100.0
    msg = ""
    if failed:
        msg = "Tickers omitidos por error de descarga: " + ", ".join(prettify_symbol(t) for t in failed)
    return var.dropna().sort_values(), msg

def plot_top_bottom(real_returns: pd.Series, top_n: int, bottom_n: int,
                    start_label: str, end_label: str, normalize_flag: bool,
                    cmap_pos: str = "Blues", cmap_neg: str = "Reds") -> io.BytesIO:
    """Colorea con gradiente. Si normalize_flag=True, aclara 'Base 100=ini' en títulos."""
    rr = real_returns.dropna()
    if rr.empty:
        raise RuntimeError("No hay datos para el rango seleccionado.")
    best = rr.nlargest(top_n)
    worst = rr.nsmallest(bottom_n)

    best_min = float(best.min())
    best_max = float(best.max())
    cmap_best = colormaps.get_cmap(cmap_pos)
    if best_min == best_max:
        log.info(
            "plot_top_bottom uniform best returns value=%s; skipping normalization",
            best_min,
        )
        colors_pos = np.tile(cmap_best(0.5), (len(best), 1))
    else:
        norm_pos = Normalize(vmin=best_min, vmax=best_max)
        colors_pos = cmap_best(norm_pos(best.values))

    abs_worst = np.abs(worst)
    worst_min = float(abs_worst.min())
    worst_max = float(abs_worst.max())
    cmap_worst = colormaps.get_cmap(cmap_neg)
    if worst_min == worst_max:
        log.info(
            "plot_top_bottom uniform worst returns magnitude=%s; skipping normalization",
            worst_min,
        )
        colors_neg = np.tile(cmap_worst(0.5), (len(worst), 1))
    else:
        norm_neg = Normalize(vmin=worst_min, vmax=worst_max)
        colors_neg = cmap_worst(norm_neg(abs_worst.values))

    fig = plt.figure(figsize=(11.5, 8.5), dpi=150, constrained_layout=True)
    gs = fig.add_gridspec(2, 1, height_ratios=[1, 1], hspace=0.32)

    tag = " (Base 100=ini, USD vía CCL)" if normalize_flag else " (USD vía CCL)"

    ax1 = fig.add_subplot(gs[0, 0])
    x1 = [prettify_symbol(t) for t in best.index]
    ax1.bar(x1, best.values, color=colors_pos, edgecolor="none")
    ax1.set_title("Best Performing Tickers" + tag)
    ax1.set_ylabel("Return (%)")
    ax1.set_xticks(range(len(x1)))
    ax1.set_xticklabels(x1, rotation=45, ha="right")

    ax2 = fig.add_subplot(gs[1, 0])
    x2 = [prettify_symbol(t) for t in worst.index]
    ax2.bar(x2, worst.values, color=colors_neg, edgecolor="none")
    ax2.set_title("Worst Performing Tickers" + tag)
    ax2.set_ylabel("Return (%)")
    ax2.set_xticks(range(len(x2)))
    ax2.set_xticklabels(x2, rotation=45, ha="right")

    if start_label or end_label:
        fig.suptitle(f"Período: {start_label} → {end_label}", fontsize=10)
    bio = io.BytesIO()
    fig.savefig(bio, format="png", bbox_inches="tight")
    plt.close(fig)
    bio.seek(0)
    return bio

def plot_tickers_usd(tickers: list[str], start: str, end: str, normalize_flag: bool) -> io.BytesIO:
    """Grafica múltiples tickers en USD (vía CCL).

    Cada serie se normaliza a 100 en la fecha inicial si ``normalize_flag`` es True;
    caso contrario se muestran valores absolutos en USD.
    """
    tickers_ba = [norm_ticker_ba(t) for t in tickers]
    log.info(
        "plot_tickers_usd request tickers=%s start=%s end=%s",
        tickers_ba,
        start,
        end,
    )
    try:
        raw = yf.download(
            tickers_ba, start=start, end=end, auto_adjust=True, progress=False
        )
    except Exception as ex:
        error_id = log_exception_with_id(
            "plot_tickers_usd download failed",
            exc=ex,
            tickers=tickers_ba,
            start=start,
            end=end,
            normalize=normalize_flag,
        )
        pretty = ", ".join(prettify_symbol(t) for t in tickers_ba)
        raise RuntimeError(
            "No se pudieron descargar datos. "
            f"Revisá los logs con error_id={error_id} para {pretty}."
        ) from ex
    log.info(
        "plot_tickers_usd yf.download shape=%s", getattr(raw, "shape", None)
    )
    px = raw["Close"]
    if isinstance(px, pd.Series):
        close = px.to_frame(tickers_ba[0])
    else:
        close = px
    if isinstance(close.index, pd.DatetimeIndex):
        close.index = (
            close.index.tz_convert("UTC").tz_localize(None)
            if close.index.tz is not None
            else close.index.tz_localize(None)
        )
    log.info("plot_tickers_usd close shape=%s", getattr(close, "shape", None))

    ccl = download_ccl(start, end)
    if isinstance(ccl.index, pd.DatetimeIndex):
        ccl.index = (
            ccl.index.tz_convert("UTC").tz_localize(None)
            if ccl.index.tz is not None
            else ccl.index.tz_localize(None)
        )
    log.info("plot_tickers_usd ccl shape=%s", getattr(ccl, "shape", None))
    usd = (
        close.div(ccl, axis=0)
        .dropna(axis=1, how="all")
        .dropna(how="all")
    )
    missing = usd.columns[usd.isna().any()]
    if not missing.empty:
        log.warning("plot_tickers_usd missing data for %s", list(missing))
    log.info("plot_tickers_usd usd shape=%s", usd.shape)

    log.info(
        "plot_tickers_usd: normalize=%s, usd_shape=%s",
        normalize_flag,
        usd.shape,
    )

    if usd.empty:
        log.info(
            "plot_tickers_usd empty usd for tickers=%s (ba=%s) start=%s end=%s",
            tickers,
            tickers_ba,
            start,
            end,
        )
        raise RuntimeError("Sin datos para ese rango.")

    if normalize_flag:
        log.info("plot_tickers_usd applying normalization")
        base = usd.iloc[0]
        log.debug("plot_tickers_usd base initial=%s", base.to_dict())
        invalid = base[(base == 0) | base.isna()]
        if not invalid.empty:
            bad_cols = [prettify_symbol(c) for c in invalid.index]
            log.info("plot_tickers_usd filtering invalid base tickers=%s", bad_cols)
            log.debug(
                "plot_tickers_usd invalid base values=%s", invalid.to_dict()
            )
            log.warning(
                "plot_tickers_usd invalid base values for %s", bad_cols
            )
            base = usd.replace(0, np.nan).apply(
                lambda col: col.dropna().iloc[0] if not col.dropna().empty else np.nan
            )
            still_bad = base[base.isna()]
            if not still_bad.empty:
                bad = [prettify_symbol(c) for c in still_bad.index]
                log.error(
                    "plot_tickers_usd no valid values after cleanup for %s", bad
                )
                raise RuntimeError(
                    "No se encontraron valores válidos para normalizar: "
                    + ", ".join(bad)
                )
        log.debug("plot_tickers_usd base finalized=%s", base.to_dict())
        plot_df = usd.divide(base, axis=1) * 100.0
        ylabel = "Índice (100=ini)"
        title_tag = " – Normalizado (100=ini)"
    else:
        log.info("plot_tickers_usd normalization not applied")
        plot_df = usd
        ylabel = "USD"
        title_tag = " – USD"

    fig = None
    bio = io.BytesIO()
    try:
        fig, ax = plt.subplots(figsize=(10, 5), dpi=150)
        for col in plot_df.columns:
            ax.plot(plot_df.index, plot_df[col], label=prettify_symbol(col))

        ax.set_ylabel(ylabel)
        ax.set_xlabel("Fecha")
        ax.set_title(
            f"{', '.join(prettify_symbol(t) for t in plot_df.columns)}{title_tag} vía CCL"
        )
        ax.grid(True, alpha=0.25)
        ax.legend()

        fig.savefig(bio, format="png", bbox_inches="tight")
        log.info(
            "plot_tickers_usd plot_df columns=%s index_range=%s→%s rows=%d",
            list(plot_df.columns),
            plot_df.index.min() if not plot_df.index.empty else None,
            plot_df.index.max() if not plot_df.index.empty else None,
            len(plot_df.index),
        )
        log.info("plot_tickers_usd figure generated")
    except Exception as ex:
        error_id = log_exception_with_id(
            "plot_tickers_usd plotting failed",
            exc=ex,
            tickers=tickers_ba,
            start=start,
            end=end,
            normalize=normalize_flag,
            columns=list(plot_df.columns),
        )
        pretty = ", ".join(prettify_symbol(t) for t in tickers_ba)
        raise RuntimeError(
            "No se pudo generar el gráfico. "
            f"Revisá los logs con error_id={error_id} para {pretty}."
        ) from ex
    finally:
        if fig is not None:
            plt.close(fig)
            log.info("plot_tickers_usd figure closed")
    bio.seek(0)
    return bio

# ----------------------- HANDLERS --------------------
async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    s, e = get_dates(update.effective_chat.id)
    norm = get_normalize(update.effective_chat.id)
    msg = "Comandos: /ini YYYY-MM-DD | /fin YYYY-MM-DD | /cclvars N M | /cclplot TICKER1 [TICKER2 ...] | /normalize\n"
    msg += f"Rango actual: inicio={s or '⟂'} | fin={e or '⟂'} | normalize={norm}"
    await update.message.reply_text(msg)

async def cmd_ini(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not context.args:
        await update.message.reply_text("Formato: /ini YYYY-MM-DD")
        return
    try:
        d = parse_date(context.args[0])
        set_date(update.effective_chat.id, "start", d)
        await update.message.reply_text(f"Fecha inicial guardada: {d}")
    except Exception:
        await update.message.reply_text("Fecha inválida. Formato: YYYY-MM-DD")

async def cmd_fin(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not context.args:
        await update.message.reply_text("Formato: /fin YYYY-MM-DD")
        return
    try:
        d = parse_date(context.args[0])
        set_date(update.effective_chat.id, "end", d)
        await update.message.reply_text(f"Fecha final guardada: {d}")
    except Exception:
        await update.message.reply_text("Fecha inválida. Formato: YYYY-MM-DD")

async def cmd_normalize(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    new_val = toggle_normalize(chat_id)
    log.info("cmd_normalize chat_id=%s new_val=%s", chat_id, new_val)
    if new_val:
        txt = ("Normalización: ON\n"
               "Desde ahora TODOS los gráficos se devuelven normalizados con base **100** en la fecha inicial.\n"
               "- /cclplot: línea índice (100=ini).\n"
               "- /cclvars: rendimientos relativos; el gráfico aclara Base 100=ini.")
    else:
        txt = ("Normalización: OFF\n"
               "Desde ahora los gráficos NO se normalizan.\n"
               "- /cclplot: precio en USD (vía CCL) absoluto.\n"
               "- /cclvars: rendimientos relativos en % (sin base 100 en el título).")
    log.debug("cmd_normalize response chat_id=%s text=%r", chat_id, txt)
    await update.message.reply_text(txt, disable_web_page_preview=True)

async def cmd_cclvars(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if len(context.args) != 2:
        await update.message.reply_text("Uso: /cclvars <top_n> <bottom_n> (ej: /cclvars 15 20)")
        return
    try:
        top_n = int(context.args[0])
        bot_n = int(context.args[1])
    except ValueError:
        await update.message.reply_text("Los dos parámetros deben ser enteros.")
        return

    s, e = get_dates(update.effective_chat.id)
    if not s or not e:
        await update.message.reply_text("Definí primero el rango con /ini y /fin.")
        return

    normalize_flag = get_normalize(update.effective_chat.id)
    # Enviamos primero la respuesta al usuario antes de los cálculos pesados
    await update.message.reply_text(
        f"Calculando Top {top_n} / Bottom {bot_n} para {s} → {e} …"
    )
    try:
        # Ejecutamos tareas de cálculo en un hilo aparte para no bloquear el loop
        series, msg = await asyncio.to_thread(get_var, s, e)
        if series.dropna().empty:
            await update.message.reply_text("Sin datos para ese rango.")
            if msg:
                await update.message.reply_text(msg)
            return
        img = await asyncio.to_thread(
            plot_top_bottom, series, top_n, bot_n, s, e, normalize_flag
        )
        await update.message.reply_photo(img, caption=f"Top/Bottom {s} → {e}")
        if msg:
            await update.message.reply_text(msg)
    except RuntimeError as ex:
        msg = str(ex)
        if "error_id=" not in msg:
            error_id = log_exception_with_id(
                "cmd_cclvars runtime error",
                exc=ex,
                chat_id=update.effective_chat.id,
                top_n=top_n,
                bottom_n=bot_n,
                start=s,
                end=e,
                normalize=normalize_flag,
            )
            msg = f"{msg} (error_id={error_id})"
        await update.message.reply_text(msg)
    except Exception as ex:
        error_id = log_exception_with_id(
            "cmd_cclvars unexpected error",
            exc=ex,
            chat_id=update.effective_chat.id,
            top_n=top_n,
            bottom_n=bot_n,
            start=s,
            end=e,
            normalize=normalize_flag,
        )
        await update.message.reply_text(
            f"Error al generar gráfico: {ex} (error_id={error_id})"
        )

async def cmd_cclplot(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if len(context.args) < 1:
        await update.message.reply_text("Uso: /cclplot <TICKER1> [TICKER2 …]")
        return

    chat_id = update.effective_chat.id
    s, e = get_dates(chat_id)
    if not s or not e:
        await update.message.reply_text("Definí primero el rango con /ini y /fin.")
        return

    tickers = context.args
    tickers_norm = [norm_ticker_ba(t).upper() for t in tickers]
    tickers_str = ", ".join(tickers_norm)
    normalize_flag = get_normalize(chat_id)
    ctx_info = (f"chat_id={chat_id} tickers={tickers_norm} "
                f"start={s} end={e} normalize={normalize_flag}")
    log.info(f"cmd_cclplot start {ctx_info}")
    await update.message.reply_text(f"Graficando {tickers_str} para {s} → {e} …")
    try:
        log.info(f"cmd_cclplot to_thread start {ctx_info}")
        img = await asyncio.to_thread(plot_tickers_usd, tickers, s, e, normalize_flag)
        size = img.getbuffer().nbytes if hasattr(img, "getbuffer") else None
        if size is not None:
            log.info(f"cmd_cclplot to_thread done {ctx_info} size={size}")
        else:
            log.info(f"cmd_cclplot to_thread done {ctx_info}")
        await update.message.reply_photo(img, caption=f"{tickers_str} – {s} → {e}")
        log.info(f"cmd_cclplot response sent {ctx_info}")
    except RuntimeError as ex:
        msg = str(ex)
        if "error_id=" not in msg:
            error_id = log_exception_with_id(
                "cmd_cclplot runtime error",
                exc=ex,
                chat_id=chat_id,
                tickers=tickers_norm,
                start=s,
                end=e,
                normalize=normalize_flag,
            )
            msg = f"{msg} (error_id={error_id})"
        await update.message.reply_text(msg)
    except Exception as ex:
        error_id = log_exception_with_id(
            "cmd_cclplot unexpected error",
            exc=ex,
            chat_id=chat_id,
            tickers=tickers_norm,
            start=s,
            end=e,
            normalize=normalize_flag,
        )
        await update.message.reply_text(
            f"Error al graficar {tickers_str}: {ex} (error_id={error_id})"
        )

# ------------------------- MAIN ---------------------
def main():
    if not TOKEN or TOKEN.startswith("REEMPLAZA_"):
        raise SystemExit("Definí TELEGRAM_BOT_TOKEN en el entorno o en TOKEN.")
    app = Application.builder().token(TOKEN).build()

    app.add_handler(CommandHandler("start",     cmd_start))
    app.add_handler(CommandHandler("ini",       cmd_ini))
    app.add_handler(CommandHandler("fin",       cmd_fin))
    app.add_handler(CommandHandler("normalize", cmd_normalize))
    app.add_handler(CommandHandler("cclvars",   cmd_cclvars))
    app.add_handler(CommandHandler("cclplot",   cmd_cclplot))

    log.info("Bot listo.")
    app.run_polling(close_loop=False)

if __name__ == "__main__":
    main()

